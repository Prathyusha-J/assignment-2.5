			ASSIGNMENT 2.5


1) Explain what is a cluster and what is a hadoop cluster

HADOOP CLUSTER:      
           1) A computer cluster used for Hadoop is called Hadoop Cluster. 
           2) Hadoop clusters are comprised of three different node types: master nodes, worker nodes, and client nodes. 
           3) Hadoop cluster is a special type of computational cluster designed for storing and analyzing vast amount of unstructured data
               in a distributed computing environment. 
          4) Large Hadoop Clusters are arranged in several racks. 

             COMPONENTS: 1) Client -  plays a role of loading the data into cluster, submit MapReduce jobs describing how the data should
                                               be processed and then retrieve the data
		      2) Master - The Masters consists of 3 components NameNode, Secondary Node name and JobTracker.
		      3) Slave - Stores the data and processes  the computation.

CLUSTER :
          1) Cluster is the logical unit of file storage on a hard disk; it's managed by the computer's operating system. 
          2) A file's clusters can be scattered among different locations on the hard disk. 
          3) Since a cluster is a logical rather than a physical unit (it's not built into the hard disk itself), the size of a cluster can be varied. 
          4)The tradeoff in cluster size is that even the smallest file (and even a directory itself) takes up the entire cluster.
         
            FEATURES -  1) load balancing         2) parallel processing.             3) High availability


2) Explain the components of Hadoop 1.x

HADOOP 1.x :
HDFS stands for Hadoop Distributed File System. It is also know as HDFS V1 as it is part of Hadoop 1.x.
It is used as a Distributed Storage System in Hadoop Architecture.

COMPONENTS OF HADOOP 1.x :
1) HDFS :
	* HDFS is a Hadoop Distributed FileSystem, where our BigData is stored .
	* It is designed to work with Large DataSets with default block size is 64MB .
	* The two sub-components:
	   1)Name Node -
		 * Name Node is placed in Master Node. It used to store Meta Data about Data Nodes.
		 * Ex:Slave Node Details, Data Nodes locations, timestamps
	   2) Data Node-
		 * Data Nodes are places in Slave Nodes. It is used to store our Application Actual Data. 
		 * It stores data in Data Slots of size 64MB by default.

2) MAPREDUCE:
	* MapReduce is a Distributed Data Processing or Batch Processing Programming Model.
	*  It deals with “High Volume of Variety of Data at High Velocity Rate” 
	* The two sub-components:
	   1) Job Tracker -
                                      * Job Tracker is used to assign MapReduce Tasks to Task Trackers in the Cluster of Nodes.
		  * It reassigns same tasks to other Task Trackers as previous Task Trackers are failed.
		  * Ex: Up/running, Failed, Recovered.
	   2) Task Tracker -
		  * Task Tracker executes the Tasks which are assigned by Job Tracker .
		  * Task Tracker sends the status of those tasks to Job Tracker.

